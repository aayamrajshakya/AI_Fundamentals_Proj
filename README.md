## AI Fundamentals Group Project

### Project overview
Our project is a simple AI model that can detect hand gestures and interpret them into actionable commands. The project is related to computer vision, as it involves processing visual data (live camera input) to recognize a user's hand signs. We will use supervised learning to train the model on a dataset of sign language gestures ***(features, x)*** along with their meanings ***(labels, y)***, which will later be generalized to our live camera input.
 
f:x â†’ y, where f is the action linked to the hand gesture

<mark>Frameworks and libraries used:</mark> OpenCV, TensorFlow, Keras

-----------------------------

### Team Members

| Name              | netID  | GitHub                                                                               |
|-------------------|--------|--------------------------------------------------------------------------------------|
| Aayam Raj Shakya  | as5160 | [![GitHub](https://skillicons.dev/icons?i=github)](https://github.com/aayamrajshakya)|
| Juan Miguel Rivera| jar1139| [![GitHub](https://skillicons.dev/icons?i=github)](https://github.com/juanmigrivera) |
| Tess Harris       | emh585 | [![GitHub](https://skillicons.dev/icons?i=github)](https://github.com/tesseralia)    |
| Gabriel Asare     | ga436  | [![GitHub](https://skillicons.dev/icons?i=github)](https://github.com/gabrielasare)  |
| Taylor Pierce     | tkp122 | [![GitHub](https://skillicons.dev/icons?i=github)](https://github.com/tkpierce)      |
